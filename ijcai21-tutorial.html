<!DOCTYPE html>
<!-- saved from url=(0031)https://quanmingyao.github.io/AutoML.github.io/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
​    

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Welcome to IJCAI2021 Automated Recommender System Tutorial</title>
<meta name="generator" content="Jekyll v3.8.5">
<meta property="og:title" content="Welcome to IJCAI2021 Automated Recommender System Tutorial">
<meta property="og:locale" content="en_US">
<meta name="description" content="Welcome to IJCAI2021 Automated Recommender System Tutorial">
<meta property="og:description" content="Welcome to IJCAI2021 Automated Recommender System Tutorial">
<link rel="canonical" href="https://quanmingyao.github.io/AutoML.github.io/">
<meta property="og:url" content="https://quanmingyao.github.io/AutoML.github.io/">
<meta property="og:site_name" content="wsl-workshop.github.io">
<script type="application/ld+json">
{"@type":"WebSite","url":"https://quanmingyao.github.io/AutoML.github.io/","name":"wsl-workshop.github.io","headline":"Welcome to IJCAI2021 Automated Recommender System Tutorial","description":"Welcome to IJCAI2021 Automated Recommender System Tutorial","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="theme-color" content="#157878">
<link rel="stylesheet" href="./style.css">
</head>
<body>
<section class="page-header">
<h1 class="project-name">IJCAI2021 Tutorial</h1>
<h2 class="project-tagline">Towards Automated Recommender System, Aug, Online</h2>  

</section>

<section class="main-content">
<!--       <h2 id="May 9th, Cincinnati, Ohio, United States">May 9th, Cincinnati, Ohio, United States
</h2> -->

<!-- <h1 id="topic-summary">Zoom Recordings</h1>
<p>Check <a href="https://hkbu.zoom.us/rec/share/Zn_Cetck7GfshdlGYE160NcBsQrx2TfbmimWSjDUPdZV5L3LSC8byx3Vgj1-WmNC.WKlJu8XhID9_OC-H">Workshop Recordings</a></p> -->


<h1 id="tentative-schedule">Schedule</h1>

<p>The workshop will be held at August, 2021</p>

<p>Beijing Time (UTC+8): Aug 22 8.00 - 11.00AM</p>
<p>Montreal Time (UTC-4): Aug 21 20:00 – 2:00AM(Next day)</p>
<!-- <p>The workshop is totally free online. Check our workshop recordings</p> -->

<h1 id="topic-summary">Abstract</h1>

<p>Recommender system (RecSys) [3], which attempts to find what items a particular user wants, is an
important area in data mining and machine learning. However, as the recommender task is getting more
diverse and the recommending models are growing more complicated, it is more and more difficult to develop
a proper RecSys that can adapt well to a new recommender task. Recently, the automated machine learning
(AutoML) [1, 2], which targets at easing the usage of learning tools and designing task-dependent learning
models, has become an important and popular area with both practical needs and research values.</p>

<div style="text-align: center; width: 100%">
<img style="text-align: center; width: 60%; height: auto" alt="My Photo" src="images/autors.PNG">
<p> Figure 1: How AutoML and RecSys integrate and mutually benefit with each other.</p>
</div>


<p>
Modern RecSys contains two phases, matching, and ranking (Figure 1). In the first phase, collaborative
filtering (CF) models are employed to extract thousands of items from billion-scale items. The data input of
this phase is mainly the user-item interaction history. Thus, the key to CF models is to compute the similarity
between a user and an item through a designed interaction function. Considering the various task settings,
i.e. datasets and evaluation metrics, the best choice of interaction function can vary, which can be searched
by AutoML. In the second phase, feature-based recommender models, also known as click-through rate (CTR)
prediction models, are utilized to further rank the output of the matching model. One of the most significant
operations in this phase is to generate effective features for users and items given the input data. Therefore,
AutoML-based feature generation methods can be deployed. From a wider perspective, the model training in
both two phases is faced with the high cost of hyper-parameter tuning. Hyper-parameter optimization, a
major direction of AutoML can help reduce human efforts in tuning recommendation models. On the other
hand, the graph has been used to model the data in RecSys scenarios, and graph representation learning
methods have been proposed for RecSys, among which graph neural networks have been quite popular. Then,
AutoML, especially neural architecture search (NAS), can help reduce such efforts. Above all, AutoML can
help to build RecSys from these four aspects (see red texts in Figure 1).
</p>

<h1 id="tentative-schedule">Schedule</h1>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Event</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>8:00-8:40</td>
      <td><strong>Part 1</strong></td>
    </tr>
	<tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: An introduction to Automated Machine Learning (AutoML)</td>
    </tr>
	<tr>
      <td>&nbsp;</td>
      <td><strong>Speaker</strong>: Quanming Yao</td>
    </tr>
    <tr>
      <td>8:40-9:20</td>
      <td><strong>Part 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: </td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: </td>
    </tr>
    <tr>
      <td>9:20-9:30</td>
      <td><strong>Part 2</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Break</strong> </td>
    </tr>
    <tr>
      <td>9:30-10:10</td>
      <td><strong>Part 3</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: </td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>:</td>
    </tr>
    <tr>
      <td>10:10-10:50</td>
      <td><strong>Part 4</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Title</strong>: Automated Knowledge Graph Embedding</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
        <td><strong>Speaker</strong>: Yongqi Zhang</td>
    </tr>
	<tr>
      <td>10:50-11:00</td>
      <td><strong>Part 5</strong></td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Discussion</strong>.</td>
    </tr>
  </tbody>
</table>


<h1 id="topic-description">Slides</h1>

<p>The slides can be found here.</p>

<h1 id="organizers">Organizers</h1>

<p><a href="http://www.cse.ust.hk/~qyaoaa/">Quanming Yao</a>,  Department of Electronic Engineering, Tsinghua University / 4Paradigm Inc. Beijing. China.</p>

<p><a href="https://yzhangee.github.io/">Yongqi Zhang</a>, 4Paradigm Inc. Beijing. China.</p>



<h1 id="sponsors">References</h1>
<p>Due to the space limitation, we only list highly-related papers.</p>
<p>
1. F. Hutter, L. Kotthoff, and J. Vanschoren, Automated machine learning: methods, systems, challenges.
Springer Nature, 2019.<br>
2. Q. Yao and M. Wang, “Taking human out of learning applications: A survey on automated machine learning,” tech. rep., arXiv preprint, 2018.<br>
3. P. Resnick and H. R. Varian, “Recommender systems,” CACM, 1997.<br>
4. T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in ICLR,
2016.<br>
5. H. Zhao, Q. Yao, J. Li, Y. Song, and D. Lee, “Meta-graph based recommendation fusion over heterogeneous
information networks,” in SIGKDD, 2017.<br>
6. Q. Yao, X. Chen, J. T. Kwok, Y. Li, and C.-J. Hsieh, “Efficient neural interaction function search for
collaborative filtering,” in WebConf, 2020.<br>
7. Y. Luo, M. Wang, H. Zhou, Q. Yao, W.-W. Tu, Y. Chen, W. Dai, and Q. Yang, “AutoCross: Automatic
feature crossing for tabular data in real-world applications,” in SIGKDD, 2019.<br>
8. Y. Zheng, C. Gao, L. Chen, D. Jin, and Y. Li, “Dgcn: Diversified recommendation with graph convolu-
tional networks,” WebConf, 2021.<br>
9. B. Jin, C. Gao, X. He, D. Jin, and Y. Li, “Multi-behavior recommendation with graph convolutional
networks,” in SIGIR, 2020.<br>
10. S. Liu, C. Gao, Y. Chen, D. Jin, and Y. Li, “Learnable embedding sizes for recommender systems,” in
ICLR, 2021.<br>
11. J. Wang, P. Huang, H. Zhao, Z. Zhang, B. Zhao, and D. L. Lee, “Billion-scale commodity embedding for
e-commerce recommendation in alibaba,” in SIGKDD, 2018.<br>
12. S. Ji, S. Pan, E. Cambria, P. Marttinen and P. S. Yu, “A Survey on Knowledge Graphs: Representation, Acquisition and Applications” in TNNLS 2021.<br>
13. Z. Sun, Z. Deng, J. Nie and J. Tang, “RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space” in ICLR 2019.<br>
14. X. Wang, X. He, Y. Cao, M. Liu and T. Chua, “KGAT: Knowledge Graph Attention Network for Recommendation” in KDD 2019.<br>
15. Y. Zhang, Q. Yao, W. Dai and L. Chen, “AutoSF: Searching Scoring Functions for Knowledge Graph Embedding” in ICDE 2020.<br>
16. Y. Zhang, Q. Yao and L. Chen, “Interstellar: Searching Recurrent Architecture for Knowledge Graph Embedding” in NeurIPS 2020.<br>
</p>

</section>

</body></html>

